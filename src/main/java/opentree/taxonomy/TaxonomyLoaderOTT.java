package opentree.taxonomy;

import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.StringTokenizer;

import opentree.taxonomy.contexts.NodeIndexDescription;
import opentree.taxonomy.OTTFlag;

import org.apache.log4j.Logger;
import org.neo4j.graphalgo.GraphAlgoFactory;
import org.neo4j.graphalgo.PathFinder;
import org.neo4j.graphdb.Direction;
import org.neo4j.graphdb.Node;
import org.neo4j.graphdb.Path;
import org.neo4j.graphdb.Relationship;
import org.neo4j.graphdb.RelationshipType;
import org.neo4j.graphdb.Transaction;
import org.neo4j.graphdb.index.Index;
import org.neo4j.graphdb.index.IndexHits;
import org.neo4j.graphdb.traversal.TraversalDescription;
import org.neo4j.kernel.Traversal;

import scala.actors.threadpool.Arrays;

/**
 * This is just a class for loading in the OTT taxonomy, as generated by smasher. This class extends the
 * TaxonomyLoaderBase, which has more general loading/validating functions. Extensions to facilitate loading
 * other taxonomies, if they become necessary, should be implemented in other separate classes.
 */
public class TaxonomyLoaderOTT extends TaxonomyLoaderBase {
	
	static String graphname;
	
	// =================== instance variables elevated from within functions
	
	Index<Node> taxSources = ALLTAXA.getNodeIndex(NodeIndexDescription.TAXONOMY_SOURCES);
	Index<Node> taxaByName = ALLTAXA.getNodeIndex(NodeIndexDescription.TAXON_BY_NAME);
	Index<Node> taxaBySynonym = ALLTAXA.getNodeIndex(NodeIndexDescription.TAXON_BY_SYNONYM);
	Index<Node> taxaByNameOrSynonym = ALLTAXA.getNodeIndex(NodeIndexDescription.TAXON_BY_NAME_OR_SYNONYM);

	Index<Node> taxaByRank = ALLTAXA.getNodeIndex(NodeIndexDescription.TAXON_BY_RANK);
	Index<Node> prefTaxaByRank = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_RANK);
	
	Index<Node> prefTaxaByName = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_NAME);
	Index<Node> prefTaxaBySynonym = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_SYNONYM);
	Index<Node> prefTaxaByNameOrSynonym = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_NAME_OR_SYNONYM);
	
	Index<Node> prefTaxaByNameHigher = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_NAME_HIGHER);
	Index<Node> prefTaxaByNameOrSynonymHigher = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_NAME_OR_SYNONYM_HIGHER);

	Index<Node> prefTaxaByNameGenera = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_NAME_GENERA);
	Index<Node> prefTaxaByNameSpecies = ALLTAXA.getNodeIndex(NodeIndexDescription.PREFERRED_TAXON_BY_NAME_SPECIES);
	
	HashMap<String, Node> dbnodes = new HashMap<String, Node>();
	HashMap<String, String> parents = new HashMap<String, String>();
	HashMap<String, OTTFlag> ottFlags;
	
	HashSet<Node> dubiousNodes = new HashSet<Node>();

	Node metadatanode = null;
	
	Transaction tx;
	
	String sourceName = "";
	
	HashMap<String, ArrayList<ArrayList<String>>> synonymhash = null;
	boolean synFileExists = false;
	
	// ========================================
	
	// basic traversal method
	final TraversalDescription CHILDOF_TRAVERSAL = Traversal.description()
			.relationships( RelType.TAXCHILDOF,Direction.OUTGOING );
	
	public TaxonomyLoaderOTT(GraphDatabaseAgent gdb) {
		super(gdb);
		buildFlagMap();
	}
	
	/**
	 * Reads a taxonomy file with rows formatted as:
	 *	ott_id\t|\tott_parent_id\t|\tName\t|\trank with spaces allowed\t|\tsources\t|\tunique_name\n TODO: add flags to this description
	 *
	 *  OTT identifier - these have been kept stable relative to OTToL 1.0
	 *  OTT identifier for the parent of this taxon, or empty if none
	 *  Name (e.g. "Rana palustris")
	 *  Rank ("genus" etc.)
	 *  Sources - this takes the form tag:id,tag:id where tag is a short string identifying the source taxonomy (currently just "ncbi" or "gbif") and id is the numeric accession number within that taxonomy. Examples: ncbi:8404,gbif:2427185 ncbi:1235509
	 *  Unique name - if the name is a homonym, then the name qualified with its rank and the name of its parent taxon, e.g. "Roperia (genus in family Hemidiscaceae)"
	 *
	 *
	 * Creates nodes and TAXCHILDOF relationships for each line.
	 * Nodes get a "name" property. Relationships get "source", "childid", "parentid" properties.
	 * 
	 * Nodes are indexed in taxNames "name" key and id value.
	 * 
	 * A metadata node is created to point to the root
	 * 
	 * The line that has no parent will be the root of this tree
	 * 
	 * @param sourcename this becomes the value of a "source" property in every relationship between the taxonomy nodes
	 * @param filename file path to the taxonomy file
	 * @param synonymfile file that holds the synonym
	 */
	public void loadOTTIntoGraph(String sourcename, String filename, String synonymfile) {
		this.sourceName = sourcename;
		String str = "";
		int count = 0;
		ArrayList<String> templines = new ArrayList<String>();
		if (synonymfile.length() > 0) {
			synFileExists = true;
		}
		//preprocess the synonym file
		//key is the id from the taxonomy, the array has the synonym and the type of synonym
		if (synFileExists) {
			synonymhash = new HashMap<String, ArrayList<ArrayList<String>>>();
			try {
				BufferedReader sbr = new BufferedReader(new FileReader(synonymfile));
				while ((str = sbr.readLine()) != null) {
					StringTokenizer st = new StringTokenizer(str, "\t|\t");
					String name = st.nextToken();
					String id = st.nextToken();
					ArrayList<String> tar = new ArrayList<String>();
					tar.add(name);tar.add("from OTT");
					if (synonymhash.get(id) == null) {
						ArrayList<ArrayList<String> > ttar = new ArrayList<ArrayList<String> >();
						synonymhash.put(id, ttar);
					}
					synonymhash.get(id).add(tar);
				}
				sbr.close();
			} catch (Exception e) {
				e.printStackTrace();
				System.exit(0);
			}
			System.out.println("synonyms: " + synonymhash.size());
		}
		//finished processing synonym file

		try {
			tx = beginTx();
			//create the metadata node
			try {
				createMetadataNode();
				tx.success();
			} finally {
				tx.finish();
			}
			BufferedReader br = new BufferedReader(new FileReader(filename));
			while ((str = br.readLine()) != null) {
				count += 1;
				templines.add(str);
				if (count % transaction_iter == 0) {
					System.out.print(count);
					System.out.print("\n");
					tx = beginTx();
					try {
						for (int i = 0; i < templines.size(); i++) {

							// duplicate block 1
							processOTTInputLine(templines.get(i));
							
						}
						tx.success();
					} finally {
						tx.finish();
					}
					templines.clear();
				}
			}
			br.close();
			tx = beginTx();
			try {
				for (int i = 0; i < templines.size(); i++) {
					
					// duplicate block 2
					processOTTInputLine(templines.get(i));
					
				}
				tx.success();
			} finally {
				tx.finish();
			}
			templines.clear();

			//add the relationships
			ArrayList<String> temppar = new ArrayList<String>();
			count = 0;
			for (String key: dbnodes.keySet()) {
				count += 1;
				temppar.add(key);
				if (count % transaction_iter == 0) {
					System.out.println(count);
					tx = beginTx();
					try {
						for (int i = 0; i < temppar.size(); i++) {

							// duplicate block 1
							processOTTRels(temppar.get(i));
							
						}
						tx.success();
					} finally {
						tx.finish();
					}
					temppar.clear();
				}
			}
			tx = beginTx();
			try {
				for (int i = 0; i < temppar.size(); i++) {

					// duplicate block 2
					processOTTRels(temppar.get(i));
					
				}
				tx.success();
			} finally {
				tx.finish();
			}
		} catch(IOException ioe) {
			ioe.printStackTrace();
		}
		
		//mark all of the barrier nodes with additional metadata
		System.out.println("setting barrier nodes");
		BarrierNodes bn = new BarrierNodes(this);
		ArrayList<Node> barrierNodes = bn.getBarrierNodes();
		HashMap<String,String> barrierNodesMap = (HashMap<String,String>)bn.getBarrierNodeMap();
		TraversalDescription CHILDREN_TRAVERSAL = Traversal.description()
				.relationships( RelType.TAXCHILDOF,Direction.INCOMING );
		tx = beginTx();
		try {
			for (int i = 0; i < barrierNodes.size(); i++) {
				for (Node currentNode : CHILDREN_TRAVERSAL.traverse(barrierNodes.get(i)).nodes()) {
					currentNode.setProperty("taxcode", barrierNodesMap.get(barrierNodes.get(i).getProperty("name")));
				}
			}
			tx.success();
		} finally {
			tx.finish();
		}
		
		//start the mrcas
		System.out.println("calculating mrcas");
		try {
			tx = graphDb.beginTx();
			initMrcaForTipsAndPO(metadatanode.getSingleRelationship(RelType.METADATAFOR, Direction.OUTGOING).getEndNode());
			tx.success();
		} finally {
			tx.finish();
		}
	}
	
	/**
	 * add relationships for a processed taxon
	 * @param childId
	 */
	private void processOTTRels(String childId) {
		try {
			Relationship rel = dbnodes.get(childId).createRelationshipTo(dbnodes.get(parents.get(childId)), RelType.TAXCHILDOF);
			rel.setProperty("source", sourceName);
			rel.setProperty("childid", childId);
			rel.setProperty("parentid", parents.get(childId));

			// don't need to wait to makeottol anymore
			if (!dubiousNodes.contains(dbnodes.get(childId))) {
				Relationship prefRel = dbnodes.get(childId).createRelationshipTo(dbnodes.get(parents.get(childId)), RelType.PREFTAXCHILDOF);
				prefRel.setProperty("source", sourceName);
				prefRel.setProperty("childid", childId);
				prefRel.setProperty("parentid", parents.get(childId));
			}

		} catch(java.lang.IllegalArgumentException io) {
			io.printStackTrace();
		}
	}
	
	/**
	 * process an input line from the ott taxonomy file
	 * @param line
	 */
	private void processOTTInputLine(String line) {

		// split the input line all the way to the end. we expect trailing empty strings when flags and uniqname are not set
		String[] tokens = line.split("\t\\|\t",-1);
		int i = 0;
		String inputId = tokens[i++];
		String inputParentId = tokens[i++];
		String inputName = tokens[i++];
		String rank = tokens[i++];
		String inputSources = tokens[i++];
		String uniqname = tokens[i++];

//		System.out.println("\nincoming string: " + tokens[i]);
		
		// the last token is the flags. don't try parsing them unless they exist
		String[] flags = tokens[i] != null ? tokens[i].split("\\,") : null;
//		System.out.println("processed array: " + Arrays.toString(flags));
		
		// we determine these bits later based on flags
		boolean dubious = false;
		boolean forceVisible = false;
		
		Node tnode = createNode();

		// special case for the life node--the graph root
		if (inputName.equals("life")) {
			System.out.println("created root node and metadata link");
			metadatanode.createRelationshipTo(tnode, RelType.METADATAFOR);
		} else {
			parents.put(inputId, inputParentId);
		}
		tnode.setProperty("name", inputName);
		tnode.setProperty("uid", inputId);
		tnode.setProperty("sourceid", inputId);
		tnode.setProperty("sourcepid", inputParentId);
		tnode.setProperty("source", sourceName);
		tnode.setProperty("rank",rank);
		tnode.setProperty("input_sources",inputSources);
		tnode.setProperty("uniqname",uniqname);

//		int k=0;
		if (flags.length > 0) {
			for (String label : flags) {
				
//				System.out.println("iterating: " + label);

				if (!label.equals("")) {
					// record all flags as node properties, whether we recognize them or not
					tnode.setProperty(label, true);
//					k++;
	
					// if we recognize the flag, check if it implies additional action
					if (ottFlags.containsKey(label)) {
						OTTFlag flag = ottFlags.get(label);
	
						if (flag == OTTFlag.FORCE_VISIBLE) {
							forceVisible = true;
							if (dubiousNodes.contains(tnode)) {
								dubious = false;
								dubiousNodes.remove(tnode);
							}
						}
					
						if (!flag.includeInPrefIndexes && !forceVisible) {
							dubious = true;
							dubiousNodes.add(tnode);
						}
					}
				}
			}
		}
		
//		System.out.println("Set " + k + " flags on node " + tnode.getId());
		
		tnode.setProperty("dubious", dubious);
		taxaByName.add(tnode, "name", inputName);
		taxaByNameOrSynonym.add(tnode, "name", inputName);
		taxaByRank.add(tnode, "rank", rank);
		
		// addl indexing
		if (!dubious) {
			prefTaxaByName.add(tnode, "name", inputName);
			prefTaxaByNameOrSynonym.add(tnode, "name", inputName);
			prefTaxaByRank.add(tnode, "rank", rank);
			
			// add to the rank-specific indexes
	        if (isSpecific(rank)) {
	        	prefTaxaByNameSpecies.add(tnode, "name", inputName);
	        } else if (rank.equals("genus")) {
	        	prefTaxaByNameGenera.add(tnode, "name", inputName);
	        	prefTaxaByNameHigher.add(tnode, "name", inputName);
	        	prefTaxaByNameOrSynonymHigher.add(tnode, "name", inputName);
	        } else {
	        	prefTaxaByNameHigher.add(tnode, "name", inputName);
	        	prefTaxaByNameOrSynonymHigher.add(tnode, "name", inputName);
	        }
			
		}
		
		dbnodes.put(inputId, tnode);
		// synonym processing
		if (synFileExists) {
			if (synonymhash.get(inputId) != null) {
				ArrayList<ArrayList<String>> syns = synonymhash.get(inputId);
				for (int j = 0; j < syns.size(); j++) {
					String synName = syns.get(j).get(0);
					String synNameType = syns.get(j).get(1);
					Node synode = createNode();
					synode.setProperty("name", synName);
					synode.setProperty("uid", synode.getId());
					synode.setProperty("nametype", synNameType);
					synode.setProperty("source", sourceName);
					synode.createRelationshipTo(tnode, RelType.SYNONYMOF);
					taxaBySynonym.add(tnode, "name", synName);
					taxaByNameOrSynonym.add(tnode, "name", synName);

					// addl indexing
					if (!dubious) {
						prefTaxaBySynonym.add(tnode,"name",synName);
						prefTaxaByNameOrSynonym.add(tnode,"name",synName);
						
			            if (!isSpecific(rank)) {
			            	prefTaxaByNameOrSynonymHigher.add(tnode, "name", synName);
			            }
					}
				}
			}
		}
	}

	/**
	 * Make a map of flags by their tag strings coming in from the file so we can quickly look them up during import
	 */
	private void buildFlagMap() {
		ottFlags = new HashMap<String, OTTFlag>();
		for (OTTFlag f : OTTFlag.values()) {
			ottFlags.put(f.label, f);
		}
		System.out.println("\nUsing flags:");
		for (String flag : ottFlags.keySet()) {
			System.out.println(flag);
		}
		System.out.println("");
	}
	
	private void createMetadataNode() {
		metadatanode = createNode();
		metadatanode.setProperty("source", sourceName);
		metadatanode.setProperty("author", "open tree of life project");
		metadatanode.setProperty("weburl", "https://github.com/OpenTreeOfLife/opentree/wiki/Open-Tree-Taxonomy");
		metadatanode.setProperty("uri", "");
		metadatanode.setProperty("urlprefix", '"');
		taxSources.add(metadatanode, "source", sourceName);
	}
	
/*	HashMap<String, ArrayList<String>> globalchildren = null;
	HashMap<String,String> globalidnamemap = null;
	PathFinder<Path> finder = GraphAlgoFactory.shortestPath(Traversal.expanderForTypes(RelType.TAXCHILDOF, Direction.OUTGOING), 10000);
	HashMap<Node,Node> lastexistingmatchparents = new HashMap<Node,Node>(); */

}

